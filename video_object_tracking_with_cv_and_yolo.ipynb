{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lnina6/video-tracking-with-opencv/blob/main/video_object_tracking_with_cv_and_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lvakO7LnnyNM",
        "outputId": "40d0451d-f492-45b3-aa34-8c2927257743"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def track_ball(video_name):\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to capture video or end of video reached\")\n",
        "            break\n",
        "\n",
        "        # Convertir en espace de couleur HSV(teinte, sturation, valeur ) depuis le RGB\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # Créer un masque pour la balle de tennis jaune,\n",
        "        # filtrer et isoler des objets de couleurs specifiques\n",
        "        mask = cv2.inRange(hsv, (29, 86, 6), (64, 255, 255))  # Plage HSV pour une balle de tennis jaune typique\n",
        "\n",
        "        # Trouver les contours dans le masque\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Dessiner les contours sur l'image originale, das ce cas des cercle pour dilimiter le perimetre\n",
        "        for contour in contours:\n",
        "            # Vous pouvez utiliser cv2.minEnclosingCircle() si vous préférez des cercles\n",
        "            (x,y),radius = cv2.minEnclosingCircle(contour)\n",
        "            center = (int(x), int(y))\n",
        "            radius = int(radius)\n",
        "            cv2.circle(frame, center, radius, (0, 255, 0), 2)  # Dessiner un cercle vert\n",
        "\n",
        "        # Afficher le résultat de la détection avec cv2_imshow\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # Fermer la fenêtre avec la touche 'q'\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Libérer la ressource et fermer toutes les fenêtres ouvertes\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Utilisztion cette fonction en passant simplement le nom du fichier vidéo\n",
        "track_ball('tennis_2.mp4')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36kVi5xlSCeJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHcUwMX6rNR1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def track_ball(video_name):\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to capture video or end of video reached\")\n",
        "            break\n",
        "\n",
        "        # Appliquer un flou pour réduire le bruit\n",
        "        frame_blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
        "\n",
        "        # Convertir en espace de couleur HSV\n",
        "        hsv = cv2.cvtColor(frame_blurred, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "         # Créer un masque pour la balle vert pistache (fluorescente)\n",
        "        # Les valeurs HSV doivent être ajustées pour correspondre à votre balle spécifique.\n",
        "        # Ces valeurs sont des estimations et doivent être calibrées :\n",
        "        # Hue (Teinte) pour le vert, Saturation élevée pour la couleur fluo, Value élevée pour la luminosité\n",
        "        #mask = cv2.inRange(hsv, (40, 100, 100), (80, 255, 255))  # Ajustez ces valeurs en fonction de votre balle\n",
        "        # Créer un masque pour la balle de tennis jaune\n",
        "        mask = cv2.inRange(hsv, (25, 100, 100), (35, 255, 255))\n",
        "\n",
        "        # Trouver les contours dans le masque\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Dessiner les contours sur l'image originale\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if 0.05 < area < 6:  # Ajustez ces valeurs selon la taille attendue de la balle\n",
        "                (x,y), radius = cv2.minEnclosingCircle(contour)\n",
        "                center = (int(x), int(y))\n",
        "                radius = int(radius)\n",
        "                cv2.circle(frame, center, radius, (0, 255, 0), 2)  # Dessiner un cercle vert autour de la balle\n",
        "\n",
        "        # Afficher le résultat de la détection avec cv2_imshow\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # Fermer la fenêtre avec la touche 'q'\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Libérer la ressource et fermer toutes les fenêtres ouvertes\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Utiliser cette fonction en passant simplement le nom de votre\n",
        "\n",
        "\n",
        "# Utiliser cette fonction en passant simplement le nom de votre fichier vidéo, par exemple:\n",
        "track_ball('tennis_3.mp4')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scbXGmzHcvAj"
      },
      "outputs": [],
      "source": [
        "#prendre en consideration le changmetn de shape d el aballe\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def track_ball(video_name):\n",
        "    # Initialisation de la capture vidéo\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    while True:\n",
        "        # Lecture d'une image du flux vidéo\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to capture video or end of video reached\")\n",
        "            break\n",
        "\n",
        "        # Application d'un flou gaussien pour réduire le bruit\n",
        "        frame_blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
        "\n",
        "        # Conversion de l'image en espace couleur HSV\n",
        "        hsv = cv2.cvtColor(frame_blurred, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # Création d'un masque pour détecter les couleurs dans une plage spécifique\n",
        "        mask = cv2.inRange(hsv, (25, 100, 100), (35, 255, 255))\n",
        "\n",
        "        # Fermeture morphologique pour combler les trous dans le masque\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
        "\n",
        "        # Recherche des contours dans le masque\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            if len(contour) >= 5:  # Vérifie si le contour a au moins 5 points\n",
        "                if 0.02 < cv2.contourArea(contour) < 5:  # Filtrage des contours par aire\n",
        "                    # Ajustement et dessin de l'ellipse sur le cadre\n",
        "                    ellipse = cv2.fitEllipse(contour)\n",
        "                    cv2.ellipse(frame, ellipse, (0, 255, 0), 2)\n",
        "\n",
        "        # Affichage de l'image avec les ellipses dessinées\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # Condition de sortie sur appui de la touche 'q'\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Libération des ressources et fermeture des fenêtres\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Appel de la fonction avec le nom du fichier vidéo\n",
        "track_ball('tennis_3.mp4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiWzwrpfSEzQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pc2Mql5-xRvV",
        "outputId": "f0232d59-b907-4fb8-f7a6-6d172e796a24"
      },
      "outputs": [],
      "source": [
        "#modif pour video tennis_3, en prenant en consideraio nle shape d el aballe\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def track_ball(video_name):\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to capture video or end of video reached\")\n",
        "            break\n",
        "\n",
        "        frame_blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
        "        hsv = cv2.cvtColor(frame_blurred, cv2.COLOR_BGR2HSV)\n",
        "        mask = cv2.inRange(hsv, (25, 100, 100), (35, 255, 255))\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5)))\n",
        "\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            if cv2.contourArea(contour) > 0.02 and len(contour) >= 5:  # Ajout de la vérification du nombre de points\n",
        "                ellipse = cv2.fitEllipse(contour)\n",
        "                cv2.ellipse(frame, ellipse, (0, 255, 0), 2)\n",
        "\n",
        "        cv2_imshow(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Appel de la fonction avec le nom du fichier vidéo\n",
        "track_ball('tennis_3.mp4')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K44k0DZLzlFg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# Installer les dépendances nécessaires\n",
        "!pip install tensorflow==2.8\n",
        "!pip install tf_slim\n",
        "!pip install pycocotools\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Télécharger le modèle pré-entraîné depuis le TensorFlow Model Zoo\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "!tar -xvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Télécharger le fichier de label map\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
        "\n",
        "# Charger le modèle pré-entraîné\n",
        "model_dir = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model'\n",
        "detection_model = tf.saved_model.load(model_dir)\n",
        "\n",
        "# Charger le fichier de label map\n",
        "PATH_TO_LABELS = 'mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "# Fonction pour la détection d'objets\n",
        "def detect_fn(image):\n",
        "    # Préparez l'image comme entrée pour le modèle\n",
        "    input_tensor = tf.convert_to_tensor(image)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # Effectuer une détection\n",
        "    detections = detection_model(input_tensor)\n",
        "\n",
        "    # Formatage des résultats de la détection\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # Convertir les classes en entiers\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    return detections\n",
        "\n",
        "def track_ball(video_name):\n",
        "    # Assurez-vous que le fichier vidéo est dans le même répertoire que ce script\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        detections = detect_fn(frame)\n",
        "\n",
        "        # Visualisation des résultats\n",
        "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            frame,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes'],\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=200,\n",
        "            min_score_thresh=.30,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "        cv2_imshow(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Utiliser cette fonction en passant simplement le nom de votre fichier vidéo\n",
        "track_ball('tennis_4.mp4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "959t0Is1NtXZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# Installer les dépendances nécessaires\n",
        "!pip install tensorflow==2.8\n",
        "!pip install tf_slim\n",
        "!pip install pycocotools\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Télécharger le modèle pré-entraîné depuis le TensorFlow Model Zoo\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "!tar -xvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Télécharger le fichier de label map\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
        "\n",
        "# Charger le modèle pré-entraîné\n",
        "model_dir = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model'\n",
        "detection_model = tf.saved_model.load(model_dir)\n",
        "\n",
        "# Charger le fichier de label map\n",
        "PATH_TO_LABELS = 'mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "# Fonction pour la détection d'objets\n",
        "def detect_fn(image):\n",
        "    # Préparez l'image comme entrée pour le modèle\n",
        "    input_tensor = tf.convert_to_tensor(image)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # Effectuer une détection\n",
        "    detections = detection_model(input_tensor)\n",
        "\n",
        "    # Formatage des résultats de la détection\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # Convertir les classes en entiers\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    return detections\n",
        "\n",
        "def track_ball(video_name):\n",
        "    # Assurez-vous que le fichier vidéo est dans le même répertoire que ce script\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        detections = detect_fn(frame)\n",
        "\n",
        "        # Visualisation des résultats avec un seuil de confiance réduit\n",
        "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            frame,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes'],\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=200,\n",
        "            min_score_thresh=.15,  # Réduire le seuil de confiance\n",
        "            agnostic_mode=False)\n",
        "\n",
        "        cv2_imshow(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Utiliser cette fonction en passant simplement le nom de votre fichier vidéo\n",
        "track_ball('tennis_4.mp4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6WOY3KCsPAHG"
      },
      "outputs": [],
      "source": [
        "# Installer YOLOv5 et les dépendances nécessaires\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt  # install dependencies\n",
        "\n",
        "# Importer les bibliothèques nécessaires\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "\n",
        "# Charger le modèle YOLOv5 pré-entraîné\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, custom\n",
        "\n",
        "# Télécharger la vidéo depuis votre ordinateur\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assurez-vous que le fichier vidéo est bien téléchargé et obtenez son nom\n",
        "for file_name in uploaded.keys():\n",
        "    print(f\"Vidéo téléchargée : {file_name}\")\n",
        "\n",
        "# Utilisez le nom de fichier téléchargé dans les fonctions suivantes\n",
        "video_name = list(uploaded.keys())[0]\n",
        "\n",
        "def detect_ball_yolo(frame):\n",
        "    # Effectuer la détection d'objets\n",
        "    results = model(frame)\n",
        "\n",
        "    # Rendre les résultats sur l'image\n",
        "    frame_with_boxes = results.render()[0]\n",
        "\n",
        "    return frame_with_boxes\n",
        "\n",
        "def track_ball_yolo(video_name, output_name):\n",
        "    # Ouvrir la vidéo d'entrée\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Erreur : Impossible de lire la vidéo.\")\n",
        "        return\n",
        "\n",
        "    # Obtenir les paramètres de la vidéo originale\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Définir le writer pour enregistrer la vidéo de sortie\n",
        "    out = cv2.VideoWriter(output_name, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_with_boxes = detect_ball_yolo(frame)\n",
        "\n",
        "        # Écrire le frame avec les boîtes dans la vidéo de sortie\n",
        "        out.write(frame_with_boxes)\n",
        "\n",
        "        # Afficher la frame avec les boîtes (optionnel)\n",
        "        cv2_imshow(frame_with_boxes)\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % 10 == 0:\n",
        "            print(f\"Traitement du frame {frame_count}\")\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    print(\"Traitement terminé. Vidéo enregistrée sous\", output_name)\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Utiliser le nom de fichier vidéo téléchargé\n",
        "track_ball_yolo(video_name, 'output_tennis_4.mp4')\n",
        "\n",
        "# Visualiser la vidéo de sortie directement dans Colab\n",
        "from IPython.display import Video\n",
        "Video(\"output_tennis_4.mp4\", embed=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GdR6SuZaUmpw",
        "outputId": "ee50b8c0-49e0-4968-8fca-cc06088b8260"
      },
      "outputs": [],
      "source": [
        "# Installer YOLOv5 et les dépendances nécessaires\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt  # install dependencies\n",
        "\n",
        "# Importer les bibliothèques nécessaires\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "\n",
        "# Charger le modèle YOLOv5 pré-entraîné\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5l')  # Utiliser un modèle plus grand pour de meilleures performances\n",
        "\n",
        "# Télécharger la vidéo depuis votre ordinateur\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assurez-vous que le fichier vidéo est bien téléchargé et obtenez son nom\n",
        "for file_name in uploaded.keys():\n",
        "    print(f\"Vidéo téléchargée : {file_name}\")\n",
        "\n",
        "# Utilisez le nom de fichier téléchargé dans les fonctions suivantes\n",
        "video_name = list(uploaded.keys())[0]\n",
        "\n",
        "def detect_ball_yolo(frame):\n",
        "    # Effectuer la détection d'objets\n",
        "    results = model(frame)\n",
        "\n",
        "    # Extraire les résultats de la détection\n",
        "    detections = results.xyxy[0].cpu().numpy()\n",
        "\n",
        "    # Rendre les résultats sur l'image\n",
        "    frame_with_boxes = results.render()[0]\n",
        "\n",
        "    return detections, frame_with_boxes\n",
        "\n",
        "def initialize_trackers():\n",
        "    return []\n",
        "\n",
        "def update_trackers(trackers, frame):\n",
        "    boxes = []\n",
        "    new_trackers = []\n",
        "    for tracker, label in trackers:\n",
        "        success, box = tracker.update(frame)\n",
        "        if success:\n",
        "            boxes.append((box, label))\n",
        "            new_trackers.append((tracker, label))\n",
        "    return new_trackers, boxes\n",
        "\n",
        "def add_detections_to_trackers(trackers, detections, frame):\n",
        "    for detection in detections:\n",
        "        x1, y1, x2, y2, conf, cls = detection\n",
        "        if conf > 0.5:  # Utiliser un seuil de confiance pour les nouvelles détections\n",
        "            tracker = cv2.TrackerCSRT_create()  # Utiliser CSRT tracker pour un suivi plus robuste\n",
        "            bbox = (int(x1), int(y1), int(x2 - x1), int(y2 - y1))\n",
        "            tracker.init(frame, bbox)\n",
        "            label = model.names[int(cls)]  # Obtenir le nom de l'objet détecté\n",
        "            trackers.append((tracker, label))\n",
        "    return trackers\n",
        "\n",
        "def track_ball_yolo(video_name, output_name):\n",
        "    # Ouvrir la vidéo d'entrée\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Erreur : Impossible de lire la vidéo.\")\n",
        "        return\n",
        "\n",
        "    # Obtenir les paramètres de la vidéo originale\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Définir le writer pour enregistrer la vidéo de sortie\n",
        "    out = cv2.VideoWriter(output_name, fourcc, fps, (width, height))\n",
        "\n",
        "    trackers = initialize_trackers()\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_count % 25 == 0:  # Mettre à jour les détections toutes les 30 frames\n",
        "            detections, frame_with_boxes = detect_ball_yolo(frame)\n",
        "            trackers = add_detections_to_trackers(trackers, detections, frame)\n",
        "        else:\n",
        "            trackers, boxes = update_trackers(trackers, frame)\n",
        "            for box, label in boxes:\n",
        "                x, y, w, h = [int(v) for v in box]\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
        "            frame_with_boxes = frame\n",
        "\n",
        "        # Écrire le frame avec les boîtes dans la vidéo de sortie\n",
        "        out.write(frame_with_boxes)\n",
        "\n",
        "        # Afficher la frame avec les boîtes (optionnel)\n",
        "        cv2_imshow(frame_with_boxes)\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % 10 == 0:\n",
        "            print(f\"Traitement du frame {frame_count}\")\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    print(\"Traitement terminé. Vidéo enregistrée sous\", output_name)\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Utiliser le nom de fichier vidéo téléchargé\n",
        "track_ball_yolo(video_name, 'output_tennis_4.mp4')\n",
        "\n",
        "# Visualiser la vidéo de sortie directement dans Colab\n",
        "from IPython.display import Video\n",
        "Video(\"output_tennis_4.mp4\", embed=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVMTx1SS9wfwYsWg/jEHQE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}